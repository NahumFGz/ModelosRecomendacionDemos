{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1. Tensorflow for recsys.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+pSzLkYKpONHOJ1NzbRgJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NahumFGz/ModelosRecomendacionDemos/blob/master/1.%20Tensorflow/1_Tensorflow_for_recsys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo Tensorflow\n",
        "https://blog.tensorflow.org/2020/09/introducing-tensorflow-recommenders.html\n",
        "https://www.tensorflow.org/recommenders/examples/basic_retrieval#building_a_candidate_ann_index"
      ],
      "metadata": {
        "id": "bXOwkyzI8FfX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGEz9pHY5oH4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30198a30-e6db-4de9-b046-65fa181364d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow-recommenders\n",
        "!pip install -q --upgrade tensorflow-datasets\n",
        "!pip install -q scann"
      ],
      "metadata": {
        "id": "022cSdJj5vHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad79ba66-07f7-4c68-b8e1-1bd2fea76926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.2 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.7 MB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 25 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 62.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 58.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 579 kB/s \n",
            "\u001b[K     |████████████████████████████████| 462 kB 50.7 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pprint\n",
        "import tempfile\n",
        "\n",
        "from typing import Dict, Text\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "24EddMoz52i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparing the dataset"
      ],
      "metadata": {
        "id": "qJ13iypz_tJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings data.\n",
        "ratings = tfds.load(\"movie_lens/100k-ratings\", split=\"train\")\n",
        "# Features of all the available movies.\n",
        "movies = tfds.load(\"movie_lens/100k-movies\", split=\"train\")"
      ],
      "metadata": {
        "id": "DRW8LHC46kJZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252d5219-246f-45a6-d234-b6c41f7b0d87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:The handle \"movie_lens\" for the MovieLens dataset is deprecated. Prefer using \"movielens\" instead.\n",
            "WARNING:absl:The handle \"movie_lens\" for the MovieLens dataset is deprecated. Prefer using \"movielens\" instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The ratings dataset returns a dictionary of movie id, user id, the assigned rating, timestamp, movie information, and user information:\n",
        "\n",
        "for x in ratings.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvwS6FGb7--7",
        "outputId": "04a74df1-bf1b-4c71-cb77-dbd31ec7d4cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bucketized_user_age': 45.0,\n",
            " 'movie_genres': array([7]),\n",
            " 'movie_id': b'357',\n",
            " 'movie_title': b\"One Flew Over the Cuckoo's Nest (1975)\",\n",
            " 'raw_user_age': 46.0,\n",
            " 'timestamp': 879024327,\n",
            " 'user_gender': True,\n",
            " 'user_id': b'138',\n",
            " 'user_occupation_label': 4,\n",
            " 'user_occupation_text': b'doctor',\n",
            " 'user_rating': 4.0,\n",
            " 'user_zip_code': b'53211'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The movies dataset contains the movie id, movie title, and data on what genres it belongs to. Note that the genres are encoded with integer labels.\n",
        "\n",
        "for x in movies.take(1).as_numpy_iterator():\n",
        "  pprint.pprint(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPX457q99WmS",
        "outputId": "71f905cb-1daa-4a1c-c8d2-f8f261c22e79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'movie_genres': array([4]),\n",
            " 'movie_id': b'1681',\n",
            " 'movie_title': b'You So Crazy (1994)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example, we're going to focus on the ratings data.  <----------------------------------\n",
        "# Other tutorials explore how to use the movie information data as well to improve the model quality.\n",
        "# We keep only the `user_id`, and `movie_title` fields in the dataset.\n",
        "\n",
        "ratings = ratings.map(lambda x: {\n",
        "    \"movie_title\": x[\"movie_title\"],\n",
        "    \"user_id\": x[\"user_id\"],\n",
        "})\n",
        "movies = movies.map(lambda x: x[\"movie_title\"])"
      ],
      "metadata": {
        "id": "ako3VabK9ZmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To fit and evaluate the model, we need to split it into a training and evaluation set. \n",
        "# In an industrial recommender system, this would most likely be done by time: the data up to time  T  would be used to predict interactions after  T .\n",
        "# In this simple example, however, let's use a random split, putting 80% of the ratings in the train set, and 20% in the test set.\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
        "\n",
        "train = shuffled.take(80_000)\n",
        "test = shuffled.skip(80_000).take(20_000)"
      ],
      "metadata": {
        "id": "cq3DJcE69pOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's also figure out unique user ids and movie titles present in the data.\n",
        "# This is important because we need to be able to map the raw values of our categorical features to embedding vectors in our models.  <------------------------------------------------------\n",
        "# To do that, we need a vocabulary that maps a raw feature value to an integer in a contiguous range: this allows us to look up the corresponding embeddings in our embedding tables.\n",
        "\n",
        "movie_titles = movies.batch(1_000)\n",
        "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
        "\n",
        "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
        "unique_user_ids = np.unique(np.concatenate(list(user_ids)))\n",
        "\n",
        "unique_movie_titles[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRT5Iby0-_PL",
        "outputId": "93bfd00f-5b2c-4987-adb6-7da97a9b2ae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b\"'Til There Was You (1997)\", b'1-900 (1994)',\n",
              "       b'101 Dalmatians (1996)', b'12 Angry Men (1957)', b'187 (1997)',\n",
              "       b'2 Days in the Valley (1996)',\n",
              "       b'20,000 Leagues Under the Sea (1954)',\n",
              "       b'2001: A Space Odyssey (1968)',\n",
              "       b'3 Ninjas: High Noon At Mega Mountain (1998)',\n",
              "       b'39 Steps, The (1935)'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a model"
      ],
      "metadata": {
        "id": "jza5I2rB_vtT"
      }
    }
  ]
}